{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53cc0e8a",
   "metadata": {},
   "source": [
    "# 電影評論\n",
    "* data = https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data  \n",
    "submmit: https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/submit  \n",
    "* step\n",
    "### 1. [準備原始文本數據](#preprocessing)\n",
    "### 2. [BERT格式](#bertmode)\n",
    "### 3. [下游任務模型](#finetune)\n",
    "### 4. [訓練模型](#model)\n",
    "### 5. [新樣本預測](#predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff05615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "import os\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c8b25b",
   "metadata": {},
   "source": [
    "<a id = preprocessing></a>\n",
    "### 準備原始文本數據"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8311c9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/home/bettyliao/sentiment/data/kaggle_movie_reviews/train.tsv', sep = '\\t') \n",
    "test_ = pd.read_csv('/home/bettyliao/sentiment/data/kaggle_movie_reviews/test.tsv', sep = '\\t')\n",
    "print(f\"\"\"train: {train.columns.values}\\ntest: {test_.columns.values}\\n\"\"\") \n",
    "print(f\"\"\"train info: {train.info()}\\ntest info:{test_.info()}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb75e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[['Phrase', 'Sentiment']]\n",
    "test = test_[['Phrase']]\n",
    "display(train.head(), test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0863245",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Phrase'] = train['Phrase'].str.replace('\\.', '[SEP]')\n",
    "train['Phrase'] = train['Phrase'].str.replace(',', '[SEP]')\n",
    "\n",
    "test['Phrase'] = test['Phrase'].str.replace('\\.', '[SEP]')\n",
    "test['Phrase'] = test['Phrase'].str.replace(',', '[SEP]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450834c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sent_count = train.groupby(['Sentiment']).size().to_frame('count').reset_index() \n",
    "plt.figure(facecolor = 'grey')\n",
    "plt.bar(sent_count['Sentiment'], sent_count['count'])\n",
    "plt.title('Sentiment distribute')\n",
    "print('each catrgory ratio: \\n',train['Sentiment'].value_counts()/ len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15e93da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = train.sample(frac = 0.01, random_state = 123)\n",
    "train_.to_csv('/home/bettyliao/sentiment/data/kaggle_movie_reviews/train_.tsv', sep = '\\t', index = False)\n",
    "test.to_csv('/home/bettyliao/sentiment/data/kaggle_movie_reviews/test_.tsv', sep = '\\t', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16953e77",
   "metadata": {},
   "source": [
    "<a id = bertmode></a>\n",
    "### ● BERT格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a3f129",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_MODEL_NAME = 'bert-base-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME) \n",
    "vocab = tokenizer.vocab # 28996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a95c65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_['Phrase'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bba3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentiDataset(Dataset):\n",
    "    os.chdir('/home/bettyliao/sentiment/data/kaggle_movie_reviews')\n",
    "    def __init__(self, mode, tokenizer):\n",
    "        assert mode in ['train_', 'test_']\n",
    "        self.mode = mode\n",
    "        self.df = pd.read_csv(mode + '.tsv', sep = '\\t').fillna('') \n",
    "        self.len = len(self.df)\n",
    "        self.tokenizer = tokenizer\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'test_':\n",
    "            text_a = self.df.Phrase.iloc[idx]\n",
    "            text_b = ''\n",
    "            label_tensor = None\n",
    "        else:\n",
    "            text_a = self.df.Phrase.iloc[idx]\n",
    "            text_b = ''\n",
    "            label_tensor = torch.tensor(self.df.Sentiment.iloc[idx]) \n",
    "        # text_a\n",
    "        word_pieces = [\"[CLS]\"]\n",
    "        tokens_a = self.tokenizer.tokenize(text_a)\n",
    "        word_pieces += tokens_a + [\"[SEP]\"]\n",
    "        len_a = len(word_pieces)\n",
    "        \n",
    "        ids = self.tokenizer.convert_tokens_to_ids(word_pieces) \n",
    "        tokens_tensor = torch.tensor(ids)\n",
    "        segments_tensor = torch.tensor([0] * len_a, dtype = torch.long) \n",
    "        \n",
    "        return (tokens_tensor, segments_tensor, label_tensor)\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f37b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = SentiDataset('train_', tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6499ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 1\n",
    "text_a, label = trainset.df.iloc[sample_idx].values  \n",
    "tokens_tensor, segments_tensor, label_tensor = trainset[sample_idx] \n",
    "tokens = tokenizer.convert_ids_to_tokens(tokens_tensor.tolist()) \n",
    "combined_text = ' '.join(tokens)\n",
    "\n",
    "print(f\"\"\"\n",
    "[origin]\n",
    "sentence_a = {text_a}\n",
    "label = {label}\n",
    "---------------------------\n",
    "[tensors]\n",
    "tokens_tensor: {tokens_tensor}\n",
    "segments_tensor: {segments_tensor}\n",
    "label_tensor: {label_tensor}\n",
    "[text]\n",
    "{combined_text}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e345516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batch(samples):\n",
    "    tokens_tensors = [s[0] for s in samples]\n",
    "    segments_tensors = [s[1] for s in samples]\n",
    "    if samples[0][2] is not None:\n",
    "        label_ids = torch.stack([s[2] for s in samples]) \n",
    "    else:\n",
    "        label_ids = None\n",
    "    tokens_tensors = pad_sequence(tokens_tensors, batch_first = True) \n",
    "    segments_tensors = pad_sequence(segments_tensors, batch_first = True) \n",
    "    masks_tensors = torch.zeros(tokens_tensors.shape, dtype = torch.long) \n",
    "    masks_tensors = masks_tensors.masked_fill(tokens_tensors != 0, 1)  \n",
    "    return tokens_tensors, segments_tensors, masks_tensors, label_ids\n",
    "batch_size = 64\n",
    "trainloader =  DataLoader(trainset, batch_size = batch_size, collate_fn = create_mini_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fb729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(trainloader))\n",
    "\n",
    "tokens_tensors, segments_tensors, masks_tensors, label_ids = data  \n",
    "\n",
    "# tokens_tensors, segments_tensors, masks_tensors因長度不同需padding  \n",
    "print(f\"\"\"\n",
    "tokens_tensors: {tokens_tensors.shape}\n",
    "{tokens_tensors}\n",
    "-------------------------------------\n",
    "segments_tensors: {segments_tensors.shape}\n",
    "{segments_tensors}\n",
    "------------------------------------------\n",
    "masks_tensors: {masks_tensors.shape}\n",
    "{masks_tensors}\n",
    "------------------------------------\n",
    "label_ids.shape = {label_ids.shape}\n",
    "{label_ids}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475296db",
   "metadata": {},
   "source": [
    " <a id = finetune></a>\n",
    "### ●下游任務模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2f76dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_MODEL_NAME = 'bert-base-cased'\n",
    "NUM_LABELS = 5\n",
    "model = BertForSequenceClassification.from_pretrained(PRETRAINED_MODEL_NAME, num_labels = NUM_LABELS) \n",
    "clear_output()\n",
    "\n",
    "print(\"\"\"\n",
    "name     module\n",
    "-------------------\"\"\")\n",
    "for name, module in model.named_children():\n",
    "    if name == 'bert':\n",
    "        for n, _ in module.named_children():\n",
    "            print(f'{name} : {n}')\n",
    "    else:\n",
    "        print('{:15}{}'.format(name, module))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6989b9",
   "metadata": {},
   "source": [
    "<a id = model></a>\n",
    "### ● 訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee3853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, dataloader, compute_acc=False):\n",
    "    predictions = None\n",
    "    correct = 0\n",
    "    total = 0\n",
    "      \n",
    "    with torch.no_grad():\n",
    "        # 遍巡整個資料集\n",
    "        for data in dataloader:\n",
    "            # 將所有 tensors 移到 GPU 上\n",
    "            if next(model.parameters()).is_cuda:\n",
    "                data = [t.to(\"cuda:0\") for t in data if t is not None]\n",
    "            \n",
    "            \n",
    "            # 別忘記前 3 個 tensors 分別為 tokens, segments 以及 masks\n",
    "            # 且強烈建議在將這些 tensors 丟入 `model` 時指定對應的參數名稱\n",
    "            tokens_tensors, segments_tensors, masks_tensors = data[:3]\n",
    "            outputs = model(input_ids=tokens_tensors, \n",
    "                            token_type_ids=segments_tensors, \n",
    "                            attention_mask=masks_tensors)\n",
    "            \n",
    "            logits = outputs[0]\n",
    "            _, pred = torch.max(logits.data, 1)\n",
    "            \n",
    "            # 用來計算訓練集的分類準確率\n",
    "            if compute_acc:\n",
    "                labels = data[3]\n",
    "                total += labels.size(0)\n",
    "                correct += (pred == labels).sum().item()\n",
    "                \n",
    "            # 將當前 batch 記錄下來\n",
    "            if predictions is None:\n",
    "                predictions = pred\n",
    "            else:\n",
    "                predictions = torch.cat((predictions, pred))\n",
    "    \n",
    "    if compute_acc:\n",
    "        acc = correct / total\n",
    "        return predictions, acc\n",
    "    return predictions\n",
    "    \n",
    "# 讓模型跑在 GPU 上並取得訓練集的分類準確率\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "model = model.to(device)\n",
    "_, acc = get_predictions(model, trainloader, compute_acc=True)\n",
    "print(\"初始 classification acc:\", round(acc * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f676ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learnable_params(module):\n",
    "    return [p for p in module.parameters() if p.requires_grad] \n",
    "\n",
    "model_params = get_learnable_params(model)\n",
    "clf_params = get_learnable_params(model.classifier)\n",
    "\n",
    "print(f'''\n",
    "整體模型參數： {sum(p.numel() for p in model_params)}\n",
    "線性模型參數: {sum(p.numel() for p in clf_params)}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe404a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.train()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-5) \n",
    "EPOCHS = 6  #\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for data_ in trainloader:\n",
    "        \n",
    "        tokens_tensors, segments_tensors, \\\n",
    "        masks_tensors, labels = [t.to(device) for t in data_]\n",
    "\n",
    "        # 將參數梯度歸零\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(input_ids = tokens_tensors, \n",
    "                        token_type_ids = segments_tensors, \n",
    "                        attention_mask = masks_tensors, \n",
    "                        labels = labels)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # 紀錄當前 batch loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    # 計算分類準確率\n",
    "    _, acc = get_predictions(model, trainloader, compute_acc=True)\n",
    "\n",
    "    print('[epoch %d] loss: %.3f, acc: %.3f' %\n",
    "          (epoch + 1, running_loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460b3ea9",
   "metadata": {},
   "source": [
    "<a id = predict></a>\n",
    "### ● 新樣本預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474e1b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "testset = SentiDataset('test_', tokenizer = tokenizer)\n",
    "testloader = DataLoader(testset, batch_size = 256, collate_fn = create_mini_batch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95be45ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = get_predictions(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124e2c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Sentiment': predictions.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6e4fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([test_['PhraseId'], df], axis = 1)\n",
    "final.Sentiment = final.Sentiment.astype('str')\n",
    "final.Sentiment = final.Sentiment.str.replace('.0', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef7c057",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb7a326",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('/home/bettyliao/sentiment/output/bert_result.csv', index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f274b1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13abbc58",
   "metadata": {},
   "source": [
    "參考資料：  \n",
    "https://medium.com/programming-with-data/32-transformer-%E9%A0%90%E8%A8%93%E7%B7%B4-%E9%9B%86%E5%A4%A7%E6%88%90%E7%9A%84-bert-%E6%A8%A1%E5%9E%8B-c928530f6db8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
