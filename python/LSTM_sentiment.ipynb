{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36b0fac5",
   "metadata": {},
   "source": [
    "data: https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data  \n",
    "code:  \n",
    "https://www.kaggle.com/shyambhu/sentiment-classification-using-lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84821ad3",
   "metadata": {},
   "source": [
    "## Steps\n",
    "step1 > [LOAD DATA](#load_data)  \n",
    "step2 > [DATA_CLEANING](#cleaning)  \n",
    "step3 > [model](#model)  \n",
    "step4 > [Classification_Report](#class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe78bcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import re\n",
    "\n",
    "from keras.models import Sequential\n",
    "import keras\n",
    "from keras.layers import Dense, LSTM, Activation, Embedding, Bidirectional, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931261f4",
   "metadata": {},
   "source": [
    "<a id = load_data> </a>\n",
    "## LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1488d5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 156060 entries, 0 to 156059\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   PhraseId    156060 non-null  int64 \n",
      " 1   SentenceId  156060 non-null  int64 \n",
      " 2   Phrase      156060 non-null  object\n",
      " 3   Sentiment   156060 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 4.8+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 66292 entries, 0 to 66291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   PhraseId    66292 non-null  int64 \n",
      " 1   SentenceId  66292 non-null  int64 \n",
      " 2   Phrase      66292 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 1.5+ MB\n",
      "\n",
      "train :None\n",
      "\n",
      "test :None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "pd.set_option('display.max_columns', None)\n",
    "train = pd.read_csv('/home/bettyliao/sentiment/data/kaggle_movie_reviews/train.tsv', sep = '\\t')\n",
    "test = pd.read_csv('/home/bettyliao/sentiment/data/kaggle_movie_reviews/test.tsv', sep = '\\t')\n",
    "print(f\"\"\"\n",
    "train :{train.info()}\\n\n",
    "test :{test.info()}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0ba5d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    50.99\n",
      "3    21.10\n",
      "1    17.48\n",
      "4     5.90\n",
      "0     4.53\n",
      "Name: Sentiment, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 各類別百分比\n",
    "train = train[['Phrase', 'Sentiment']]\n",
    "percent = round(train.Sentiment.value_counts()/len(train)*100,2) \n",
    "print(percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "776df9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "train['length'] = train['Phrase'].apply(lambda x: len(x.split())) \n",
    "print(train['length'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0eb49e",
   "metadata": {},
   "source": [
    "<a id = cleaning></a>\n",
    "## DATA CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b908204",
   "metadata": {},
   "source": [
    "獲取單詞在句子中的詞性，再結合詞形還原，就能很好地完成詞形還原功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42c4e5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "# convert to lower and remove stopword\n",
    "def clean_text(text):\n",
    "    stopword = set(stopwords.words('english')) # load stopwords \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = text.lower() # convert to lower\n",
    "    text = ' '.join([i for i in text.split() if i not in stopword]) \n",
    "    text = ' '.join([lemmatizer.lemmatize(i, get_wordnet_pos(i)) for i in text.split()])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87c7ce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['clean_text'] = train['Phrase'].apply(lambda x: clean_text(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5eae033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>length</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>series escapade demonstrate adage good goose a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>series escapade demonstrate adage good goose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Phrase  Sentiment  length  \\\n",
       "0  A series of escapades demonstrating the adage ...          1      37   \n",
       "1  A series of escapades demonstrating the adage ...          2      14   \n",
       "2                                           A series          2       2   \n",
       "3                                                  A          2       1   \n",
       "4                                             series          2       1   \n",
       "\n",
       "                                          clean_text  \n",
       "0  series escapade demonstrate adage good goose a...  \n",
       "1       series escapade demonstrate adage good goose  \n",
       "2                                             series  \n",
       "3                                                     \n",
       "4                                             series  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a1eea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenazation\n",
    "max_features = 10000 # max words 10000\n",
    "tokenizer = Tokenizer(num_words = max_features, split = ' ') \n",
    "tokenizer.fit_on_texts(train['clean_text'].values)\n",
    "X = tokenizer.texts_to_sequences(train['clean_text'].values) \n",
    "X = pad_sequences(X, maxlen = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809f3d78",
   "metadata": {},
   "source": [
    "<a id = model></a>\n",
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64f3a803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train.shape: (124848, 128),\n",
      "X_test.shape: (31212, 128),\n",
      "y_train.shape: (124848,),\n",
      "y_test.shape: (31212,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = train['Sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42) \n",
    "print(f\"\"\"\n",
    "X_train.shape: {X_train.shape},\n",
    "X_test.shape: {X_test.shape},\n",
    "y_train.shape: {y_train.shape},\n",
    "y_test.shape: {y_test.shape}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d55722c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 3, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b16aaa",
   "metadata": {},
   "source": [
    "embedding:\n",
    "1. input_dim :This is the size of the vocabulary in the text data   \n",
    "2. output_dim :This is the size of the vector space in which words will be embedded.  \n",
    "3. input_length :This is the length of input sequences, as you would define for any input layer of a Keras model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afb99dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 128)         6400000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 128)         98816     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 6,598,277\n",
      "Trainable params: 6,598,277\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "#vocal_dim = len(tokenizer) +1 \n",
    "\n",
    "model = Sequential()\n",
    "inputs = keras.Input(shape = (None, ), dtype = 'int32')\n",
    "model.add(inputs)\n",
    "model.add(Embedding(50000, embed_dim)) # pad_sequences(maxlen = 25) \n",
    "#input_dim = vocab_size, \n",
    "#output_dim = embed_dim\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dense(5, activation = \"softmax\")) # softmax 總合1\n",
    "model.summary()\n",
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "             optimizer = 'adam', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ab67f6",
   "metadata": {},
   "source": [
    "plot_model(model, show_shapes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "069d1126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3902/3902 [==============================] - 517s 133ms/step - loss: 0.8084 - accuracy: 0.6698 - val_loss: 0.8395 - val_accuracy: 0.6580\n",
      "Epoch 2/10\n",
      "3902/3902 [==============================] - 525s 135ms/step - loss: 0.7447 - accuracy: 0.6945 - val_loss: 0.8339 - val_accuracy: 0.6638\n",
      "Epoch 3/10\n",
      "3902/3902 [==============================] - 516s 132ms/step - loss: 0.6993 - accuracy: 0.7118 - val_loss: 0.8387 - val_accuracy: 0.6670\n",
      "Epoch 4/10\n",
      "3902/3902 [==============================] - 520s 133ms/step - loss: 0.6619 - accuracy: 0.7257 - val_loss: 0.8606 - val_accuracy: 0.6654\n",
      "Epoch 5/10\n",
      "3902/3902 [==============================] - 519s 133ms/step - loss: 0.6287 - accuracy: 0.7365 - val_loss: 0.8645 - val_accuracy: 0.6625\n",
      "Epoch 6/10\n",
      "3902/3902 [==============================] - 516s 132ms/step - loss: 0.5994 - accuracy: 0.7463 - val_loss: 0.9123 - val_accuracy: 0.6584\n",
      "Epoch 7/10\n",
      "3902/3902 [==============================] - 516s 132ms/step - loss: 0.5714 - accuracy: 0.7565 - val_loss: 0.9358 - val_accuracy: 0.6540\n",
      "Epoch 8/10\n",
      "3902/3902 [==============================] - 513s 132ms/step - loss: 0.5457 - accuracy: 0.7642 - val_loss: 0.9781 - val_accuracy: 0.6561\n",
      "Epoch 9/10\n",
      "3902/3902 [==============================] - 514s 132ms/step - loss: 0.5209 - accuracy: 0.7720 - val_loss: 1.0223 - val_accuracy: 0.6479\n",
      "Epoch 10/10\n",
      "3902/3902 [==============================] - 514s 132ms/step - loss: 0.4991 - accuracy: 0.7785 - val_loss: 1.0803 - val_accuracy: 0.6493\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 10, batch_size = 32, verbose = 1, validation_data = (X_test, y_test))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864cc0b7",
   "metadata": {},
   "source": [
    "<a id = class></a>\n",
    "##  Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0cf619d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred = pred.argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "688ef836",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "944d7723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.36      0.42      1416\n",
      "           1       0.54      0.54      0.54      5527\n",
      "           2       0.73      0.80      0.76     15639\n",
      "           3       0.58      0.53      0.55      6707\n",
      "           4       0.55      0.41      0.47      1923\n",
      "\n",
      "    accuracy                           0.65     31212\n",
      "   macro avg       0.58      0.53      0.55     31212\n",
      "weighted avg       0.64      0.65      0.64     31212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f79a7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2271b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b02e5a2",
   "metadata": {},
   "source": [
    "```\n",
    "def text_cleaning(text):\n",
    "    stopwords = set(stopwords.words('english'))\n",
    "    if text:\n",
    "        text = ' '.join(text.split('.'))\n",
    "        text = re.sub('\\/', ' ',text)\n",
    "        text = re.sub(r'\\\\', ' ', text)\n",
    "        text = re.sub(r'((http)\\S+)', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', \n",
    "                      re.sub('[^A-Za-z]', ' ', text.strip().lower())).strip()  \n",
    "        text = re.sub(r'\\W+', ' ', text.strip().lower()).strip()\n",
    "        text = [word for word in text.split() if word not in stopwords]\n",
    "        return text\n",
    "    return []\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
